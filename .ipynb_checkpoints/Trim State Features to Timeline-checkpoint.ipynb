{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_level_feat = pd.read_csv('Choose State Level Features.csv')\n",
    "state_feat_info = pd.read_csv('state_series_table_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229, 2)\n",
      "(85514, 8)\n"
     ]
    }
   ],
   "source": [
    "print(state_level_feat.shape)\n",
    "print(state_feat_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_state_feat = state_level_feat.title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Housing Inventory: Active Listing Count in'\n",
      " 'Housing Inventory: Active Listing Count Month-Over-Month in'\n",
      " 'Housing Inventory: Active Listing Count Year-Over-Year in' ...\n",
      " 'Deposits in Insured Commercial Nonmember Banks in'\n",
      " 'Total Deposits in Commercial Nonmember Banks in'\n",
      " 'Total Deposits in Commercial Banks in']\n",
      "(14496, 8)\n"
     ]
    }
   ],
   "source": [
    "state_feat_info.title = state_feat_info.apply(lambda row: row['title'].strip(), axis=1)\n",
    "print(state_feat_info.title.values)\n",
    "chosen_state_feat_info = state_feat_info[state_feat_info.title.isin(chosen_state_feat)]\n",
    "print(chosen_state_feat_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1502, 8)\n",
      "(12945, 8)\n"
     ]
    }
   ],
   "source": [
    "late_features = chosen_state_feat_info[chosen_state_feat_info.observation_start > '2010-01-01']\n",
    "print(late_features.shape)\n",
    "late_features_to_drop = late_features.title.unique()\n",
    "state_feat_end_trim = chosen_state_feat_info[~chosen_state_feat_info.title.isin(late_features_to_drop)]\n",
    "print(state_feat_end_trim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(826, 8)\n",
      "(11984, 8)\n"
     ]
    }
   ],
   "source": [
    "early_features = state_feat_end_trim[state_feat_end_trim.observation_end < '2017-01-01']\n",
    "print(early_features.shape)\n",
    "early_features_to_drop = early_features.title.unique()\n",
    "state_feat_trim = state_feat_end_trim[~state_feat_end_trim.title.isin(early_features_to_drop)]\n",
    "print(state_feat_trim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that we have each feature for every state that a county belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_feat_trimmed = pd.read_csv('county_features_trimmed.csv')\n",
    "unique_county_ids = county_feat_trimmed.county_id.unique()\n",
    "df_county_ids = pd.DataFrame(data=unique_county_ids, columns=['county_id'])\n",
    "county_table = pd.read_csv('clipped_county_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = df_county_ids.merge(county_table, on='county_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "states_needed = joined.state_id.unique()\n",
    "print(len(states_needed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have every county for each feature and every state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Monthly' 'Annual']\n",
      "['Annual' 'Quarterly']\n",
      "['Annual' 'Monthly']\n",
      "['Monthly' 'Annual']\n"
     ]
    }
   ],
   "source": [
    "state_freq_count = state_feat_trim.groupby('title').frequency.nunique()\n",
    "feat_with_multiple_frequencies = state_freq_count[state_freq_count > 1].index.values\n",
    "\n",
    "series_to_remove = []\n",
    "for feat in feat_with_multiple_frequencies:\n",
    "    df_cur_feat = state_feat_trim[state_feat_trim.title == feat]\n",
    "    print(df_cur_feat.frequency.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of series to remove: 1151\n",
      "(10833, 8)\n"
     ]
    }
   ],
   "source": [
    "series_to_remove = []\n",
    "\n",
    "monthly_feat = feat_with_multiple_frequencies[:-3]\n",
    "monthly_feat = list(monthly_feat)\n",
    "monthly_feat.extend(feat_with_multiple_frequencies[-2:])\n",
    "\n",
    "annual_feat = feat_with_multiple_frequencies[-3:-2]\n",
    "for feat in annual_feat:\n",
    "    df_cur_feat = state_feat_trim[state_feat_trim.title == feat]\n",
    "    series_to_remove.extend(df_cur_feat[df_cur_feat.frequency == 'Quarterly'].id.values)\n",
    "\n",
    "for feat in monthly_feat:\n",
    "    df_cur_feat = state_feat_trim[state_feat_trim.title == feat]\n",
    "    series_to_remove.extend(df_cur_feat[df_cur_feat.frequency == 'Annual'].id.values)\n",
    "\n",
    "print('Number of series to remove:', len(series_to_remove))\n",
    "df_state_feat = state_feat_trim[~state_feat_trim.id.isin(series_to_remove)]\n",
    "print(df_state_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10830, 8)\n"
     ]
    }
   ],
   "source": [
    "# Remove states that are not needed\n",
    "df_state_feat_final = df_state_feat[df_state_feat.state_id.isin(states_needed)]\n",
    "print(df_state_feat_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01\n",
      "2017-01-01\n",
      "181\n",
      "51\n",
      "Index(['Not in Labor Force: Discouraged Workers for',\n",
      "       'Job Losers and Persons Who Completed Temporary Jobs, as a Percent of the Civilian Labor Force for',\n",
      "       'Insured Unemployment Rate in', 'Initial Claims in',\n",
      "       'State Unemployment Benefits in', 'Civilian Labor Force for',\n",
      "       'Coincident Economic Activity Index for', 'Resident Population in',\n",
      "       'Rental Vacancy Rate for', 'Continued Claims (Insured Unemployment) in',\n",
      "       'Covered Employment in',\n",
      "       'Number of Civilians Unemployed for 15 Weeks or Longer for',\n",
      "       'Real Trade-Weighted Value of the dollar for',\n",
      "       'Real Total Gross Domestic Product for', 'Homeownership Rate for',\n",
      "       'Home Vacancy Rate for', 'Employed Involuntary Part-Time for',\n",
      "       'Employment Level for', 'Total Gross Domestic Product for',\n",
      "       'Leading Index for', 'Real Median Household Income in',\n",
      "       'All-Transactions House Price Index for',\n",
      "       'Persons Unemployed 15 Weeks or Longer, as a Percent of the Civilian Labor Force for',\n",
      "       'Total Unemployed, Plus Discouraged Workers, Plus All Other Marginally Attached Workers, as a Percent of the Civilian Labor Force Plus All Marginally Attached Workers for',\n",
      "       'Total Unemployed, as a Percent of the Civilian Labor Force for',\n",
      "       'Total Unemployed, Plus All Marginally Attached Workers, Plus Total Employed Part Time for Economic Reasons, as a Percent of the Civilian Labor Force Plus All Marginally Attached Workers for',\n",
      "       'Total Unemployed Plus Discouraged Workers, as a Percent of the Civilian Labor Force Plus Discouraged Workers for',\n",
      "       'Per Capita Personal Income in', 'All Marginally Attached Workers for',\n",
      "       'Unemployed: Job Losers for', 'Unemployment Level for',\n",
      "       'Total Personal Income in'],\n",
      "      dtype='object', name='title')\n"
     ]
    }
   ],
   "source": [
    "# Check that we have each feature for each state\n",
    "print(df_state_feat_final.observation_start.max())\n",
    "print(df_state_feat_final.observation_end.min())\n",
    "print(df_state_feat_final.title.nunique())\n",
    "print(df_state_feat_final.state_id.nunique())\n",
    "agg_state = df_state_feat_final.groupby('title').state_id.count()\n",
    "print(agg_state.sort_values().head(32).index)\n",
    "# print(agg_state[agg_state > 51].title.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{27290}\n"
     ]
    }
   ],
   "source": [
    "red_states = df_state_feat_final[df_state_feat_final.title.str.match('Not in Labor Force')].state_id.unique()\n",
    "all_states = df_state_feat_final.state_id.unique()\n",
    "print(set(all_states) - set(red_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to DC. How many counties does DC have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     county_id                  name  state_id\n",
      "232    33508.0  District of Columbia     27290\n"
     ]
    }
   ],
   "source": [
    "print(county_table[county_table.state_id == 27290])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we will drop county 33508 from the dataset, and drop state 27290."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10694, 8)\n"
     ]
    }
   ],
   "source": [
    "df_state_feat_out = df_state_feat_final[~(df_state_feat_final.state_id == 27290)]\n",
    "print(df_state_feat_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01\n",
      "2017-01-01\n",
      "181\n",
      "50\n",
      "title\n",
      "Accommodation and Food Services Earnings in                                           50\n",
      "Poverty Universe, Age 5-17 related for                                                50\n",
      "Poverty Universe, All Ages for                                                        50\n",
      "Poverty, Child Tax Exemptions for                                                     50\n",
      "Professional and Technical Services Earnings in                                       50\n",
      "                                                                                    ... \n",
      "Average Weekly Earnings of Production Employees: Manufacturing in                    100\n",
      "Average Weekly Earnings of All Employees: Trade, Transportation, and Utilities in    100\n",
      "Average Weekly Earnings of All Employees: Professional and Business Services in      100\n",
      "New Private Housing Units Authorized by Building Permits for                         100\n",
      "All Employees: Wholesale Trade in                                                    102\n",
      "Name: state_id, Length: 181, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check that we have each feature for each state\n",
    "print(df_state_feat_out.observation_start.max())\n",
    "print(df_state_feat_out.observation_end.min())\n",
    "print(df_state_feat_out.title.nunique())\n",
    "print(df_state_feat_out.state_id.nunique())\n",
    "agg_state_out = df_state_feat_out.groupby('title').state_id.count()\n",
    "print(agg_state_out.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we have duplicate series or something for some things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642\n"
     ]
    }
   ],
   "source": [
    "df_out_adj_count = df_state_feat_out.groupby('title').seasonal_adjustment.nunique()\n",
    "df_out_mult_adj = df_out_adj_count[df_out_adj_count > 1].index.values\n",
    "\n",
    "series_to_remove = []\n",
    "for feat in df_out_mult_adj:\n",
    "    df_cur_feat = df_state_feat_out[df_state_feat_out.title == feat]\n",
    "    series_to_remove.extend(df_cur_feat[df_cur_feat.seasonal_adjustment == 'Not Seasonally Adjusted'].id.values)\n",
    "\n",
    "print(len(series_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove series that are not seasonally adjusted and keep the seasonally adjusted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9052, 8)\n"
     ]
    }
   ],
   "source": [
    "df_out_fin = df_state_feat_out[~df_state_feat_out.id.isin(series_to_remove)]\n",
    "print(df_out_fin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01\n",
      "2017-01-01\n",
      "181\n",
      "50\n",
      "title\n",
      "Accommodation and Food Services Earnings in                      50\n",
      "Professional and Technical Services Earnings in                  50\n",
      "Professional and Technical Services Wages and Salaries in        50\n",
      "Projected Business Formations Within 4 Quarters for              50\n",
      "Projected Business Formations within 8 Quarters for              50\n",
      "                                                                 ..\n",
      "Implicit Regional Price Deflator: Metropolitan Portion for       50\n",
      "Implicit Regional Price Deflator: Nonmetropolitan Portion for    50\n",
      "Imports of Goods for                                             50\n",
      "Exports of Goods for                                             50\n",
      "All Employees: Wholesale Trade in                                52\n",
      "Name: state_id, Length: 181, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check that we have each feature for each state\n",
    "print(df_out_fin.observation_start.max())\n",
    "print(df_out_fin.observation_end.min())\n",
    "print(df_out_fin.title.nunique())\n",
    "print(df_out_fin.state_id.nunique())\n",
    "agg_fin = df_out_fin.groupby('title').state_id.count()\n",
    "print(agg_fin.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we still have something going on with All Employees: Wholesale Trade in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id                              title  \\\n",
      "30612    SMS22000004100000001  All Employees: Wholesale Trade in   \n",
      "30798  SMU22000004100000001SA  All Employees: Wholesale Trade in   \n",
      "\n",
      "      observation_start observation_end frequency                 units  \\\n",
      "30612        1990-01-01      2020-02-01   Monthly  Thousands of Persons   \n",
      "30798        1990-01-01      2017-01-01   Monthly  Thousands of Persons   \n",
      "\n",
      "       seasonal_adjustment  state_id  \n",
      "30612  Seasonally Adjusted     27300  \n",
      "30798  Seasonally Adjusted     27300  \n",
      "                           id                              title  \\\n",
      "67609    SMS45000004100000001  All Employees: Wholesale Trade in   \n",
      "67769  SMU45000004100000001SA  All Employees: Wholesale Trade in   \n",
      "\n",
      "      observation_start observation_end frequency                 units  \\\n",
      "67609        1990-01-01      2020-02-01   Monthly  Thousands of Persons   \n",
      "67769        1990-01-01      2020-02-01   Monthly  Thousands of Persons   \n",
      "\n",
      "       seasonal_adjustment  state_id  \n",
      "67609  Seasonally Adjusted     27323  \n",
      "67769  Seasonally Adjusted     27323  \n"
     ]
    }
   ],
   "source": [
    "temp = df_out_fin[df_out_fin.title.str.match('All Employees: Wholesale')]\n",
    "# print(temp.sort_values('state_id'))\n",
    "print(temp[temp.state_id == 27300])  \n",
    "print(temp[temp.state_id == 27323])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop SMS22000004100000001 and SMS45000004100000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state_features_out = df_out_fin[~df_out_fin.id.isin(['SMS22000004100000001', 'SMS45000004100000001'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01\n",
      "2017-01-01\n",
      "181\n",
      "50\n",
      "title\n",
      "Accommodation and Food Services Earnings in                      50\n",
      "Professional and Technical Services Earnings in                  50\n",
      "Professional and Technical Services Wages and Salaries in        50\n",
      "Projected Business Formations Within 4 Quarters for              50\n",
      "Projected Business Formations within 8 Quarters for              50\n",
      "                                                                 ..\n",
      "Implicit Regional Price Deflator for                             50\n",
      "Implicit Regional Price Deflator: Metropolitan Portion for       50\n",
      "Implicit Regional Price Deflator: Nonmetropolitan Portion for    50\n",
      "Imports of Goods: Manufactured Commodities for                   50\n",
      "Wholesale Trade Wages and Salaries in                            50\n",
      "Name: state_id, Length: 181, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check that we have each feature for each state\n",
    "print(df_state_features_out.observation_start.max())\n",
    "print(df_state_features_out.observation_end.min())\n",
    "print(df_state_features_out.title.nunique())\n",
    "print(df_state_features_out.state_id.nunique())\n",
    "agg_fin = df_state_features_out.groupby('title').state_id.count()\n",
    "print(agg_fin.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must drop DC from the county features too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158046, 9)\n",
      "(157982, 9)\n"
     ]
    }
   ],
   "source": [
    "df_county_feat_trimmed = pd.read_csv('county_features_trimmed.csv')\n",
    "print(df_county_feat_trimmed.shape)\n",
    "df_county_feat_out = df_county_feat_trimmed[df_county_feat_trimmed.county_id != 33508]\n",
    "print(df_county_feat_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_county_feat_out.to_csv('county_features_final.csv')\n",
    "df_state_features_out.to_csv('state_features_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
